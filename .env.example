# Third party tools
USE_WANDB=False
WANDB_API_KEY=
WANDB_ENTITY=
WANDB_PROJECT=
USE_HUGGINGFACE=False
HUGGINGFACE_TOKEN=
# Dataset arguments
## Language of the dataset (ex. tr, en, fr, etc.)
LANGUAGE=
## Wiki access token can be obtained from https://api.wikimedia.org/wiki/Special:AppManagement
WIKI_ACCESS_TOKEN=
## Whether or not to assume numeric keywords as entity
CONVERT_NUMERIC_TO_ENTITY=False

# Training arguments
## Path of the created dataset.
DATASET=
## Huggingface checkpoint for the base model to finetune (ex. bert-base-uncased)
CHECKPOINT=
## Type of the task (extractor or discriminator)
TASK_TYPE=
## Named of the resulting finetuned model.
MODEL_NAME=
## Sample size of the training dataset.
SAMPLE_SIZE=30000
## Number of epochs.
EPOCHS=8
## Batch size of the training dataset.
BATCH_SIZE=16
## Learning rate for the model.
LEARNING_RATE=2e-5

# Post-Training arguments
PUBLISH_TO_HUGGINGFACE=False